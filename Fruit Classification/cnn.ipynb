{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1 Initializing CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2 adding 1st Convolution layer and Pooling layer\n",
    "classifier.add(Convolution2D(32,(3,3),input_shape = (64,64,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3 adding 2nd convolution layer and polling layer\n",
    "classifier.add(Convolution2D(32,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step4 Flattening the layers\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step5 Full_Connection\n",
    "classifier.add(Dense(units=32,activation = 'relu'))\n",
    "classifier.add(Dense(units=64,activation = 'relu'))\n",
    "classifier.add(Dense(units=128,activation = 'relu'))\n",
    "classifier.add(Dense(units=256,activation = 'relu'))\n",
    "classifier.add(Dense(units=256,activation = 'relu'))\n",
    "classifier.add(Dense(units=6,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step6 Compiling CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#step7 Fitting CNN to images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True) # To rescaling the image in range of [0,1] # To randomly shear the images  # To randomly zoom the images#  for randomly flipping half of the images horizontally \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "print(\"\\nTraining the data...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1212 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\SAGAR\\Documents\\ashwini\\latest project\\Fruit Classification-20200916T075844Z-001\\Dataset-20200916T075906Z-001\\Dataset\\train',target_size=(64,64),batch_size=12,class_mode='categorical')#Total no. of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\SAGAR\\Documents\\ashwini\\latest project\\Fruit Classification-20200916T075844Z-001\\Dataset-20200916T075906Z-001\\Dataset\\test',target_size=(64,64),batch_size=12,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\logs\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\logs\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=2, epochs=20, validation_steps=300)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 31s 16s/step - loss: 0.1091 - accuracy: 0.9583 - val_loss: 0.2715 - val_accuracy: 0.8500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 34s 17s/step - loss: 0.4771 - accuracy: 0.7917 - val_loss: 0.3417 - val_accuracy: 0.8500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 31s 15s/step - loss: 0.5171 - accuracy: 0.8333 - val_loss: 0.6022 - val_accuracy: 0.8767\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.5535 - accuracy: 0.8333 - val_loss: 0.2102 - val_accuracy: 0.8733\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 29s 15s/step - loss: 0.3232 - accuracy: 0.8750 - val_loss: 0.5846 - val_accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 32s 16s/step - loss: 0.2703 - accuracy: 0.9167 - val_loss: 0.4282 - val_accuracy: 0.8700\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.1830 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.8700\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 31s 16s/step - loss: 0.2139 - accuracy: 0.9583 - val_loss: 0.3705 - val_accuracy: 0.8767\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.2810 - accuracy: 0.9167 - val_loss: 0.2267 - val_accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 29s 15s/step - loss: 0.2709 - accuracy: 0.8750 - val_loss: 0.5357 - val_accuracy: 0.8567\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.5522 - accuracy: 0.8333 - val_loss: 0.4117 - val_accuracy: 0.8600\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8533\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 29s 15s/step - loss: 0.1225 - accuracy: 0.9583 - val_loss: 0.0484 - val_accuracy: 0.8433\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 28s 14s/step - loss: 0.2284 - accuracy: 0.9583 - val_loss: 0.0619 - val_accuracy: 0.8467\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 28s 14s/step - loss: 0.3230 - accuracy: 0.9167 - val_loss: 0.8537 - val_accuracy: 0.8600\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 28s 14s/step - loss: 0.2756 - accuracy: 0.8333 - val_loss: 0.3673 - val_accuracy: 0.8467\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 28s 14s/step - loss: 0.4745 - accuracy: 0.8750 - val_loss: 0.1942 - val_accuracy: 0.8733\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 27s 14s/step - loss: 0.3832 - accuracy: 0.7917 - val_loss: 0.8996 - val_accuracy: 0.9033\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 27s 14s/step - loss: 0.0933 - accuracy: 0.9583 - val_loss: 0.3687 - val_accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 27s 14s/step - loss: 0.5798 - accuracy: 0.7917 - val_loss: 0.0779 - val_accuracy: 0.8933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fb55b40cc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,samples_per_epoch=30,nb_epoch = 20,validation_data = test_set,nb_val_samples = 300) # Total testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step8 saving model \n",
    "\n",
    "classifier.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
